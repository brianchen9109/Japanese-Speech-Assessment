{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\envs\\voice\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"jakeyoo/whisper-medium-ja\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"jakeyoo/whisper-medium-ja\")\n",
    "model.config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "#convert dataset Function library\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 225/225 [00:05<00:00, 42.60 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "sentence = [\"～さい\",\"あなた\",\"あのかた\",\"あのひと\",\"いしゃ\",\"エンジニア\",\"おいくつ\",\n",
    "            \"かいしゃいん\",\"がくせい\",\"きょうし\",\"ぎんこういん\",\"けんきゅうしゃ\",\"しゃいん\",\n",
    "            \"せんせい\",\"だいがく\",\"だれ\",\"でんき\",\"どなた\",\"なんさい\",\"びょういん\",\"みなさん\",\n",
    "            \"わたし\",\"わたしたち\"]\n",
    "df = {\n",
    "    \"path\": [],\n",
    "    \"word\": [],\n",
    "}\n",
    "\n",
    "for index in range(len(sentence)):\n",
    "    for word in sentence:\n",
    "        path = f\"..\\\\audio\\cliped_audio\\A_class\\A_class_audio_{index}\\{word}.mp3\"\n",
    "        if(os.path.isfile(path)):\n",
    "            df[\"path\"].append(path)\n",
    "            df[\"word\"].append(word)\n",
    "#print(len(df[\"path\"]))\n",
    "#print(len(df[\"word\"]))\n",
    "\n",
    "test_dataset = {\"path\":df[\"path\"]}\n",
    "test_dataset = pd.DataFrame(test_dataset)\n",
    "#print(test_dataset)\n",
    "test_dataset = Dataset(pa.Table.from_pandas(test_dataset))\n",
    "#print(test_dataset[\"path\"])\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = librosa.load(batch[\"path\"], sr=16_000)\n",
    "    batch[\"array\"] = speech_array\n",
    "    #batch[\"sentence\"] = batch[\"sentence\"].upper()\n",
    "    return batch\n",
    "\n",
    "test_dataset = test_dataset.map(speech_file_to_array_fn)\n",
    "input_features = processor(test_dataset[\"array\"], sampling_rate=16_000, return_tensors=\"pt\").input_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50266, 50359,  ..., 50257, 50257, 50257],\n",
       "        [50258, 50266, 50359,  ..., 50257, 50257, 50257],\n",
       "        [50258, 50266, 50359,  ..., 50257, 50257, 50257],\n",
       "        ...,\n",
       "        [50258, 50266, 50359,  ..., 50257, 50257, 50257],\n",
       "        [50258, 50266, 50359,  ..., 50257, 50257, 50257],\n",
       "        [50258, 50266, 50359,  ..., 50257, 50257, 50257]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate token ids\n",
    "predicted_ids = model.generate(input_features)\n",
    "predicted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcription: ['さい。', 'あなた。', 'あの方。', 'あの人。', '一冊。', 'エンジニア。', 'おいくつ。', '会社会', '学生。', '教師。', '原稿令。', '研究者。', '下位', '先生。', '大英学。', '誰？', '天気。', 'どうなった？', '何歳！', '', '皆さん、', 'わたし。', '私たち。', 'さい。', 'あなた。', 'あのカッター。', 'あの人。', '医者。', 'エンジニア', 'おいくつ？', '会社員。', '学生。', '教師。', '銀行印。', '研究者。', '下位', '先生。', '大学。', 'だめ。', '電気。', 'どなた？', '何歳！', '病院', '皆さん、', 'わたし。', '私たち。', 'したい', 'あなた。', 'あなた。', 'あの糸。', '医者。', 'エンジニア', 'おいくつ？', '会社員', '学生。', '教師。', '銀行印', '研究者', '社員。', '先生。', '大学', '誰？', '電気。', 'となった。', '何歳！', '病院。', '皆さん、', 'わたし。', '私たち。', 'さい。', 'あなた。', 'あの人。', '医者', 'エンジニア', 'おいくつ？', '会社員', '学生。', '教師。', '銀行印', '研究者', '社員。', '先生。', '内学', '誰？', '電気。', 'どうなった。', '何歳！', '病院', '皆さん、', 'わたし、', '私たち。', 'さい。', 'あなた。', 'あなた。', 'あの人。', '一箱', 'エンジニア', 'おいくつ？', '開箱飲', '学生。', '教師。', '丁酷癮', '研究者。', 'しゃいん', '先生。', '大学。', '誰？', '元気。', 'ほとんどになった。', 'なんさ。', '有音。', 'みなさん、', 'わたし。', '私たち。', 'さい。', 'あなた！', 'あの方？', 'あの人。', '一写。', 'エンジニア。', 'おいくつ？', '会社へ。', '学生。', '教師。', 'コウィン', '研究者', 'しゃい。', '先生。', '大学。', 'あれ？', 'ありがとう。', 'そうなった。', '何歳！', '病院。', 'みなさ。', 'わたし。', '私たち！', 'さい。', 'あなた。', 'あの方。', 'あの人。', '医者。', 'エンジニア', '老い靴', '会社員。', '学生', '教師。', '貧困院', '研究者', '社員。', '先生。', '大医学', '誰？', '電気。', 'どうなった？', '何歳！', '病院。', 'みなさん、', 'わたし。', '私たち。', 'ない。', 'あなた。', 'あの方。', 'あの人。', '一社。', 'エンジニア', 'おいくつ？', '会社員', '学生。', '教師。', '銀行印。', '研究者。', '社員。', '先生。', '大学', '', '元気', 'となった。', '何歳？', '病院。', '皆さん、', 'わたし。', '私たち。', 'さい。', 'あなた。', 'あの方。', 'あの人。', '医者。', 'エンジニア。', '老い靴。', '会社会員。', '学生。', '教師。', '銀行印。', '研究者。', '社員。', '先生。', '大学。', 'やられ。', '電気。', '何歳！', '病院。', 'みなさん。', 'わたし。', '私たち。', 'さん。', 'あなた。', 'あらへんの？', 'いい匂い', 'エンジニア', '会社員', 'なんかクセ。', '教師。', '銀が多い。', '言及者', 'シャイン', '先生。', '大学。', '誰？', '天気。', '感謝。', '表現。', 'みなさん。', 'わたし。', '私たち。']\n"
     ]
    }
   ],
   "source": [
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "print(\"transcription:\",transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\"さい。\",\"あなた。\",\"あの方。\",\"あの人。\",\"医者。\",\n",
    "            \"エンジニア。\",\"おいくつ。\",\"会社員。\",\"学生。\",\"教師。\",\n",
    "            \"ぎんこういん。\",\"研究者。\",\"しゃいん。\",\"先生。\",\"大学。\",\n",
    "            \"誰。\",\"電気。\",\"どなた。\",\"何歳！\",\"病院。\",\n",
    "            \"皆さん。\",\"わたし。\",\"私たち。\",\"さい。\",\"あなた。\",\n",
    "            \"あの方。\",\"あの人。\",\"医者。\",\"エンジニア。\",\"おいくつ。\",\n",
    "            \"会社員。\",\"学生。\",\"教師。\",\"ぎんこういん。\",\"研究者。\",\n",
    "            \"しゃいん。\",\"先生。\",\"大学。\",\"誰。\",\"電気。\",\n",
    "            \"どなた。\",\"何歳！\",\"病院。\",\"皆さん。\",\"わたし。\",\n",
    "            \"私たち。\",\"さい。\",\"あなた。\",\"あの方。\",\"あの人。\",\n",
    "            \"医者。\",\"エンジニア。\",\"おいくつ。\",\"会社員。\",\"学生。\",\n",
    "            \"教師。\",\"ぎんこういん。\",\"研究者。\",\"しゃいん。\",\"先生。\",\n",
    "            \"大学。\",\"誰。\",\"電気。\",\"どなた。\",\"何歳！\",\n",
    "            \"病院。\",\"皆さん。\",\"わたし。\",\"私たち。\",\"さい。\",\n",
    "            \"あなた。\",\"あの人。\",\"医者。\",\"エンジニア。\",\n",
    "            \"おいくつ。\",\"会社員。\",\"学生。\",\"教師。\",\"ぎんこういん。\",\n",
    "            \"研究者。\",\"しゃいん。\",\"先生。\",\"大学。\",\"誰。\",\n",
    "            \"電気。\",\"どなた。\",\"何歳！\",\"病院。\",\"皆さん。\",\n",
    "            \"わたし。\",\"私たち。\",\"さい。\",\"あなた。\",\"あの方。\",\n",
    "            \"あの人。\",\"医者。\",\"エンジニア。\",\"おいくつ。\",\"会社員。\",\n",
    "            #-----------------------\n",
    "            \"学生。\",\"教師。\",\"ぎんこういん。\",\"研究者。\",\"しゃいん。\",\n",
    "            \"先生。\",\"大学。\",\"誰。\",\"電気。\",\"どなた。\",\n",
    "            \"何歳！\",\"病院。\",\"皆さん。\",\"わたし。\",\"私たち。\",\n",
    "            \"さい。\",\"あなた。\",\"あの方。\",\"あの人。\",\"医者。\",\n",
    "            \"エンジニア。\",\"おいくつ。\",\"会社員。\",\"学生。\",\"教師。\",\n",
    "            \"ぎんこういん。\",\"研究者。\",\"しゃいん。\",\"先生。\",\"大学。\",\n",
    "            \"誰。\",\"電気。\",\"どなた。\",\"何歳！\",\"病院。\",\n",
    "            \"皆さん。\",\"わたし。\",\"私たち。\",\"さい。\",\"あなた。\",\n",
    "            \"あの方。\",\"あの人。\",\"医者。\",\"エンジニア。\",\"おいくつ。\",\"会社員。\",\n",
    "            \"学生。\",\"教師。\",\"ぎんこういん。\",\"研究者。\",\"しゃいん。\",\n",
    "            \"先生。\",\"大学。\",\"誰。\",\"電気。\",\"どなた。\",\n",
    "            \"何歳！\",\"病院。\",\"みなさん、\",\"わたし。\",\"私たち。\",\n",
    "            \"さい。\",\"あなた。\",\"あの方。\",\"あの人。\",\"医者。\",\n",
    "            \"エンジニア。\",\"おいくつ。\",\"会社員。\",\"学生。\",\"教師。\",\n",
    "            \"ぎんこういん。\",\"研究者。\",\"しゃいん。\",\"先生。\",\"大学。\",\n",
    "            \"誰。\",\"電気。\",\"どなた。\",\"何歳！。\",\"病院。\",\n",
    "            \"皆さん、\",\"わたし。\",\"私たち。\",\"さい。\",\"あなた。\",\n",
    "            \"あの方。\",\"あの人。\",\"医者。\",\"エンジニア。\",\"おいくつ。\",\n",
    "            \"会社員。\",\"学生。\",\"教師。\",\"ぎんこういん。\",\"研究者。\",\n",
    "            \"しゃいん。\",\"先生。\",\"大学。\",\"誰。\",\"電気。\",\n",
    "            #---------------------------\n",
    "            \"何歳！。\",\"病院。\",\"みなさん。\",\"わたし。\",\n",
    "            \"私たち。\",\"さい。\",\"あなた。\",\"あの人。\",\n",
    "            \"医者。\",\"エンジニア。\",\"会社員。\",\"学生。\",\n",
    "            \"教師。\",\"ぎんこういん。\",\"研究者。\",\"しゃいん。\",\"先生。\",\n",
    "            \"大学。\",\"誰。\",\"電気。\",\"何歳！\",\n",
    "            \"病院。\",\"みなさん。\",\"わたし。\",\"私たち。\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map:   0%|          | 0/225 [00:00<?, ? examples/s]c:\\Users\\admin\\anaconda3\\envs\\voice\\lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:511: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "c:\\Users\\admin\\anaconda3\\envs\\voice\\lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:697: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Map: 100%|██████████| 225/225 [01:53<00:00,  1.98 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.333333333333332\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "import torch\n",
    "from evaluate import load\n",
    "\n",
    "#librispeech_test_clean = load_dataset(\"librispeech_asr\", \"clean\", split=\"test\")\n",
    "\n",
    "test_dataset = {\"path\":df[\"path\"],\"text\":sentence}\n",
    "test_dataset = pd.DataFrame(test_dataset)\n",
    "\n",
    "test_dataset = Dataset(pa.Table.from_pandas(test_dataset))\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"jakeyoo/whisper-medium-ja\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"jakeyoo/whisper-medium-ja\").to(\"cuda\")\n",
    "\n",
    "def map_to_pred(batch):\n",
    "    \n",
    "    speech_array, sampling_rate = librosa.load(batch[\"path\"], sr=16_000)\n",
    "    batch[\"array\"] = speech_array\n",
    "    input_features = processor(batch[\"array\"], sampling_rate=16_000, return_tensors=\"pt\").input_features\n",
    "    batch[\"reference\"] = processor.tokenizer._normalize(batch['text'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(input_features.to(\"cuda\"))[0]\n",
    "    transcription = processor.decode(predicted_ids)\n",
    "    batch[\"prediction\"] = processor.tokenizer._normalize(transcription)\n",
    "    return batch\n",
    "\n",
    "result = test_dataset.map(map_to_pred)\n",
    "\n",
    "wer = load(\"wer\")\n",
    "print(100 * wer.compute(references=result[\"reference\"], predictions=result[\"prediction\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
